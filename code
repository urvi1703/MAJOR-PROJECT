import os
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import streamlit as st
import sounddevice as sd
import wavio

# 1. Load and Explore Data
def load_audio_files(directory):
    labels = []
    features = []
    for label in os.listdir(directory):
        class_dir = os.path.join(directory, label)
        if os.path.isdir(class_dir):
            for file in os.listdir(class_dir):
                file_path = os.path.join(class_dir, file)
                y, sr = librosa.load(file_path, sr=22050)
                mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
                features.append(np.mean(mfcc, axis=1))
                labels.append(label)
    return np.array(features), np.array(labels)

# Load dataset
X, y = load_audio_files("dataset_path")
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# 2. Build CNN Model
model = Sequential([
    Dense(128, activation='relu', input_shape=(40,)),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(len(set(y)), activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train Model
history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=16)

# 3. Evaluate Model
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)
print(classification_report(y_test, predicted_classes))

# 4. Streamlit Deployment
def record_audio(duration=5, filename="recorded.wav"):
    fs = 44100  # Sample rate
    print("Recording...")
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float32')
    sd.wait()
    wavio.write(filename, audio, fs, sampwidth=2)
    print("Recording saved!")

def classify_audio(file_path):
    y, sr = librosa.load(file_path, sr=22050)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
    feature = np.mean(mfcc, axis=1).reshape(1, -1)
    prediction = model.predict(feature)
    return label_encoder.inverse_transform([np.argmax(prediction)])[0]

st.title("Drone Detection and Classification")
file = st.file_uploader("Upload an audio file", type=["wav", "mp3"])
if file:
    st.audio(file, format='audio/wav')
    label = classify_audio(file)
    st.write(f"Predicted Class: {label}")

if st.button("Record Live Audio"):
    record_audio()
    label = classify_audio("recorded.wav")
    st.write(f"Predicted Class: {label}")
